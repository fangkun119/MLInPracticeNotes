# 02. Machine Learning Project

## 1.测试和验证
模型训练：训练集（记录训练误差） + 验证集（验证泛化误差）<br/> 
但是测试集仍然不够，训练很多轮之后，模型的泛化误差有可能仅仅在验证集上效果好 <br/>
需要再保留一部分样本用做测试集，用于最后一轮测试 <br/> 

方法：用K-Fold交叉验证来找到最优超参数（K-Fold可以避免浪费样本数据），确定超参数之后，使用该超参数在全量训练集上再训练一轮，最后再在测试集上测试最后一轮

## 2.典型项目过程
(1) 业务目标时什么、属于哪一类的机器学习任务 <br/>
(2) 确定模型后，确定损失函数（训练优化目标）时什么 <br/>
> 以线性回归为例：使用2范数（均方根误差）、还是1范数？<br/>
> 范数的指数越高、关注越大的误差值、忽略越小的误差值、对异常值更敏感 <br/>

(3) 了解使用方如何使用项目的输出，避免对任务产生误解 <br/>
(4) 开发环境以及相关类库、数据集 <br/>
(5) 数据查看和清洗 <br/>
> 数据schema和描述 <br/>
> 有缺失值的字段 <br/>
> 统计属性（数量，均值，最小最大值，标准差，25%50%75%百分位数值，直方图查看各区值分布）<br/>
> 注意因为某些因为上限截断而导致数据失真的字段（可能需要移除、或者为他们换一个标签）<br/>
> 数值缩放 <br/>
> 对重尾数据做转化使其接近钟形分布（例如计算对数）<br/>

(6) 测试集生成（训练集测试集拆分）：
> 该保持一致的拆分方法时，要避免重新随机 P53 P54 <br/>
> 保证分层抽样一致性 P53 P54 <br/>

(7) 可视化和探索数据，寻找特征
> 可视化，如地理位置可视化等 <br/>
> 寻找属性之间的相关性：皮尔逊相关系数（但是只能找到线性相关关系）<br/>
> 绘制属性之间相关性散点图 <br/>
> 尝试组合特征，例如：`total_rooms/house_num`, `bed_rooms/total_rooms`, `population/house_hold_num` <br/>

(8) 将上面步骤固化成代码 <br/>
(9) 训练模型、尝试不同的模型评估训练集损失值（与数据经验值做比较，来初步估算效果）、使用交叉验证评估验证集损失值。根据是欠拟合还是过拟合决定下一步怎么做。通过随机森林等模型输出的特征重要程度来查看选择的特征 <br/>
(10) 找出几个候选模型，对参数进行微调，使用GridSearchCV或RandomSearchCV <br/>
(11) 用测试集的数据评估调参后的最佳模型 <br/>
(12) 启动、监控和维护系统 <br/>

## 3. 数据清洗Transformer
(1) 有缺失值的数据：丢弃行、丢弃字段、设默认值（0，平均数、中位数、…）<br/>
(2) LabelEncoder/OneHotEncoder/DummyEncoder/...：<br/> 
> 文本Label使用OneHot编码（不使用Enum直接映射成整数的原因时，Label之间没有距离远近的概念）

(3) 特征缩放：<br/>
> (a)最大-最小缩放、即归一化、使用MinMaxScaler <br/>
> (b)标准化、减去均值除以方差使其分布具有单位方差受异常值影响更小，使用StandadScaler 

(4) 使用Pipeline将各个转化器串起来<br/>

## 4. 数据清洗技巧
(1) 根据字符串编辑距离对拼写错误的单词做模糊替换 <br/>
(2) 有些字段需要从字符串转换成ID <br/>
(3) 有些数据（值域长尾）做对数变换 <br/>
(4)	有些数据需要根据给定的分界值进行分组，或者简单分成若干份 <br/>
(5)	有些数据需要做one-hot编码（不希望原始特征之间产生关联，例如`28*2=56`）<br/>
(6)	用PCA从n个特征中选出影响力最高的`k<n`个特征 <br/>
(7)	用随机森林变种算法Isolation Forest做异常值清洗 <br/>
(8)	可能需要做特征组合、或者多项式特征 <br/>

## 5.样本不均的处理方法，例如A类样本比B类多很多时
(1)	样本充足时，让Majority类别欠采样 <br/>
> 方法1: 随机欠采样 <br/>
> 方法2: Majority类样本分成若干份、每份与Minority类一起训练一个模型，若干个模型组成一个随机森林 <br/>
> 方法3: 基于聚类的A类分割 

(2) 样本不足时，让B类过采样（重采样）
> 用随机插值法来合成B类数据: STMOE (Synthetic Minority Over-Sampling Tech)

(3)	代价敏感学习（Cost Sensitive Learning）
> 降低A类权值、提高B类权值

## 6.连续特征如何划分成离散特征
(1) 基于等分区间段之间信息熵变化情况 
> `(max - min) / step_len` 分成n份，遍历这n份，计算熵值变化，哪个点熵值变化大，哪个点适合用作分割点（缺点：超参数n取值小时精度不够；取值大时计算量太大）

(2)	基于样本间隔区间段之间的信息熵变化情况 
> N个样本，得到N-1个区间，用这N-1个区间的中值作为分割点，最多计算N-1次（其中有些分割点不影响分类效果、没必要计算）

(3)	随机选择K次分割点，计算信息熵，选择变化最大的那次

> 其实该方法使用最多、越是随机、越能对抗样本分布带来的问题

## 7.用Isolation Forest检查连续特征的异常值
Step1：	随机选特征随机选分割点，生成一颗有一定深度的决策树，计算样本x从根到叶子节点的长度`f(x)` <br/>
Step2：	重复step1一共`i`次，训练`i`棵树，计算样本x在`i`棵树中`f(x)`总和`F(x)` <br/>
Step3：	若样本`X`为异常值，它应当在大多数iTree中很快就从根节点到达叶子节点了，即`F(x)`比较小 <br/>
> [https://blog.csdn.net/ye1215172385/article/details/79762317](https://blog.csdn.net/ye1215172385/article/details/79762317) <br/>
> [https://www.jianshu.com/p/5af3c66e0410?utm_campaign=maleskine](https://www.jianshu.com/p/5af3c66e0410?utm_campaign=maleskine)

# 附录：机器学习项目清单

### [1]. 步骤
机器学习项目清单该清单可以帮助你完成你的机器学习项目。主要有8步：

1. 架构问题，关注蓝图。
2. 获取数据。
3. 研究数据以获取灵感。
4. 准备数据以更好地将低层模型暴露给机器学习算法。
5. 研究各种不同的模型，并列出最好的模型。
6. 微调模型，并将其组合为更好的解决方案。
7. 提出解决方案。
8. 启动、监视、维护系统。

当然，为了满足需求，你可以随时调整这个清单。

### [2] 架构问题，关注蓝图

1. 用商业术语定义目标。
2. 方案如何使用？
3. 目前的解决方案/办法是什么？
4. 应该如何架构问题（有监督/无监督，在线/离线，等等）？
5. 如何测量性能？
6. 性能指标是否与业务目标一致？

### [3] 获取数据

注意：尽可能的自动化，以便获取最新数据。

1. 列出需要的数据及其体量。
2. 查找并记录获取数据的途径。
3. 检查需要的空间。
4. 检查法律义务，必要时获取授权。
5. 获取访问权限。
6. 创建工作空间（确保具有足够的存储空间）。
7. 获取数据。
8. 将数据转换为可操作的格式（不改变数据本身）。
9. 确保删除或保护敏感信息（例如，匿名）。
10. 检查数据的类型和大小（时间序列、样本、地点等）。
11. 采样一个测试数据集，放在一边，永远不要用它（没有数据窥视！）。

### [4] 研究数据

注意：试着从这些步骤的领域专家那里获取灵感。

1. 创建数据的副本用于研究（如果需要，可以将其抽样为可管理的大小）。
2. 创建一个Jupyter笔记本来记录数据研究。
3. 研究每个属性及其特征：·名字。·类型（分类、整型/浮点型、有界/无界、文本、结构等）。·缺失值的百分比。·噪音和噪音类型（随机、异常、舍入误差等）。·可能有用的任务？·分布类型（高斯、统一、对数等）。
4. 对于有监督的学习任务，确认目标属性。
5. 可视化数据。
6. 研究属性之间的相关性。
7. 研究如何手动解决问题。
8. 确定希望使用转换。
9. 确定可能有用的额外数据（回到之前的“获取数据”部分）。
10. 记录学习到的东西。

### [5] 准备数据

注意：

* 在数据的副本上工作（保持原始数据集不变）。
* 编写适用于所有数据转换的函数，

原因有五个：

* 可以很容易地准备下一次得到新数据时的数据。
* 可以在未来的项目中使用这些转换。
* 清理和准备测试数据集。
* 一旦解决方案失效，用来清理和准备新数据实例。
* 可以轻松地将你的准备选择作为超参数。

1. 数据清理：

	* 修复或删除异常值（可选）。
	* 填充缺失值（例如，使用零、平均数、中位数等）或删除该行（或列）。

2. 特征选择（可选）：

	* 删除不能为任务提供任何有用信息的属性。

3. 在适当情况下，处理特征：

	* 离散连续特征。
	* 分解特征（如，分类、日期/时间等）。
	* 添加期望的特征转换（如，log(x)、sqrt(x)、x<sup>2</sup>等）。
	* 聚合特征称为期望的新特征。

### [6] 列出期望的模型

注意：

* 如果数据很大，可能需要采样为较小的训练集，以便于在合理的时间内训练不同的模型（注意，这会对诸如大型神经集或随机森林等复杂模型造成不利影响）。
* 再次，尽可能地自动化这些步骤。

1. 使用标准参数，从不同类别（例如，线性、朴素贝叶斯、SVM、随机森林、神经网络等）中训练需求快速的不成熟的模型。
2. 测量并比较它们的性能。

	* 对于每个模型，使用N倍交叉验证并计算N次折叠的性能测试的均值和标准差。

3. 分析每个算法最重要的变量。
4. 分析模型产生的错误类型。

	* 人类用什么样的数据避免这些错误？

5. 快速进行特征选择和处理。
6. 对前面五步进行一两次快速迭代。
7. 列出前三到五个最有希望的模型，倾向于选择有不同错误类型的模型。

### [7] 微调系统

注意：

* 你将希望为这一步使用尽可能多的数据，特别是在微调结束时。
* 永远尽可能地自动化。

1. 使用交叉验证微调超参数。

	* 把数据转换选择当作超参数，尤其是不确定时（例如，应该用零或者平均值填充缺失值吗？或者直接删除它？）。
	* 除非需要研究的超参数值很少，否则更喜欢在网格搜索上随机搜索。如果训练很长，你可能更喜欢贝叶斯优化方法（例如，如JasperSnoek、HugoLarochelle和RyanAdams所述，使用高斯过程进行先验（[https://goo.gl/PEFfGr](https://goo.gl/PEFfGr)））。

		>  [1]“PracticalBayesianOptimizationofMachineLearningAlgorithms”，J.Snoek、H.Larochelle和R.Adams（2012）。

2. 尝试组合方法。组合多个好模型往往比单独运行效果好。
3. 一旦你对最终模型有信心，在测试集上测量它的性能以估计泛化误差。测量泛化误差后，不要调整模型：只需要开始过度拟合测试集。

### [8] 展示解决方案

1. 文档化你所做的工作。
2. 创建完美的演示。

	* 首先确保突出蓝图。

3. 解释为什么你的解决方案达到了业务目标。
4. 不要忘记展示你发现的一些有趣的地方。

	* 描述什么可以工作，什么不行。
	* 列出你的假设和系统的局限。

5. 确保你的关键发现被完美展示或易于记忆的陈述。

### [9] 启动

1. 准备好生产环境的解决方案（插入生产数据输入，写单元测试等）。
2. 编写监控代码，定期检查系统的性能，出问题时及时报警。

	* 同样需要考虑缓慢退化：随着数据的增加，模型往往会“腐烂”。
	* 测量性能可能需要人工流水线（例如，众包服务）。
	* 同时监控输入质量（例如，发送随机值的故障传感器，或其他团队的输出过时）。这对在线学习系统尤为重要。

3. 定期对新数据重新建模（尽可能自动化）。







